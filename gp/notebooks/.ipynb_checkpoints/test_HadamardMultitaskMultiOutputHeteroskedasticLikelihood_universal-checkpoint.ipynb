{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroskedastic Multitask Multi-Output Regression\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates how to perform multitask regression across multiple multi-output models, while using a heteroskedastic noise model fit on observed measurement noise. \n",
    "\n",
    "In many practial applications, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import gpytorch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.likelihoods import (\n",
    "    _GaussianLikelihoodBase,\n",
    "    GaussianLikelihood,\n",
    "    _MultitaskGaussianLikelihoodBase,\n",
    "    MultitaskGaussianLikelihood,\n",
    "    MultitaskGaussianLikelihoodKronecker,\n",
    "    HeteroskedasticNoise,\n",
    ")\n",
    "\n",
    "\n",
    "class HadamardMultitaskGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, num_tasks, rank):\n",
    "        super(HadamardMultitaskGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        shape = train_x.shape if torch.is_tensor(train_x) else train_x[0].shape\n",
    "        ard_num_dims = None if len(shape) < 2 else shape[-1]\n",
    "        self.covar_module = gpytorch.kernels.RBFKernel(ard_num_dims=ard_num_dims)\n",
    "        self.task_covar_module = gpytorch.kernels.IndexKernel(num_tasks=num_tasks, rank=rank)\n",
    "\n",
    "    def forward(self, x, i):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        covar_i = self.task_covar_module(i)\n",
    "        covar = covar_x.mul(covar_i)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple \"task\" tasks - i.e. offline vs. online batches, or multiple online batches. For each \"task\" task we have multiple outcomes.\n",
    "\n",
    "Let's start with the simplest case of 2 \"task\" tasks and 2 outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True\n",
    "dtype = torch.float\n",
    "\n",
    "device = torch.device(\"cuda\") if cuda else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first \"task\" task\n",
    "\n",
    "train_x11 = torch.linspace(0, 1, 75, dtype=dtype, device=device)\n",
    "train_x12 = torch.linspace(0, 1, 50, dtype=dtype, device=device)\n",
    "\n",
    "min_sem1 = 0.1\n",
    "max_sem1 = 0.65\n",
    "\n",
    "sem_y11 = min_sem1 + (max_sem1 - min_sem1) * train_x11\n",
    "sem_y12 = max_sem1 - (max_sem1 - min_sem1) * train_x12\n",
    "\n",
    "train_y11 = torch.sin(train_x11 * (2 * math.pi)) + sem_y11 * torch.randn_like(train_x11)\n",
    "train_y12 = torch.cos(train_x12 * (2 * math.pi)) + sem_y12 * torch.randn_like(train_x12)\n",
    "\n",
    "train_y11_log_var = 2 * sem_y11.log() \n",
    "train_y12_log_var = 2 * sem_y12.log() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second \"task\" task - just a slightly shifted version of the previous task\n",
    "train_x21 = train_x11 + 0.05 * (torch.rand_like(train_x11) - 0.5)\n",
    "train_x22 = train_x12 + 0.05 * (torch.rand_like(train_x12) - 0.5)\n",
    "\n",
    "min_sem2 = 0.1\n",
    "max_sem2 = 0.65\n",
    "\n",
    "sem_y21 = max_sem2 - (max_sem2 - min_sem2) * train_x21\n",
    "sem_y22 = min_sem2 + (max_sem2 - min_sem2) * train_x22\n",
    "\n",
    "train_y21 = torch.sin((train_x21 - 0.1) * (2 * math.pi)) + sem_y21 * torch.randn_like(train_x21)\n",
    "train_y22 = torch.cos((train_x22 - 0.1) * (2 * math.pi)) + sem_y22 * torch.randn_like(train_x22)\n",
    "\n",
    "train_y21_log_var = 2 * sem_y21.log() \n",
    "train_y22_log_var = 2 * sem_y22.log() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices\n",
    "train_i11 = torch.full_like(train_y11, dtype=torch.long, device=train_y11.device, fill_value=0)\n",
    "train_i12 = torch.full_like(train_y12, dtype=torch.long, device=train_y12.device, fill_value=1)\n",
    "train_i21 = torch.full_like(train_y21, dtype=torch.long, device=train_y21.device, fill_value=2)\n",
    "train_i22 = torch.full_like(train_y22, dtype=torch.long, device=train_y22.device, fill_value=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full model input\n",
    "train_x = torch.cat([train_x11, train_x12, train_x21, train_x22])\n",
    "train_y = torch.cat([train_y11, train_y12, train_y21, train_y22])\n",
    "train_i = torch.cat([train_i11, train_i12, train_i21, train_i22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model inferring a homoskedastic noise\n",
    "\n",
    "Note that with the Hadamard model there is currently no way to learn differnt noise levels for the separate tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = GaussianLikelihood()\n",
    "model = HadamardMultitaskGPModel((train_x, train_i), train_y, likelihood, num_tasks=4, rank=4)\n",
    "\n",
    "if dtype == torch.double:\n",
    "    likelihood.double()\n",
    "    model.double()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10/100 - Loss: 0.691\n",
      "Iter 20/100 - Loss: 0.547\n"
     ]
    }
   ],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "n_iter = 100\n",
    "tic = time.time()\n",
    "for i in range(n_iter):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x, train_i)\n",
    "    loss = -mll(output, train_y, [train_x, train_i])\n",
    "    loss.backward()\n",
    "    if (i+1) % 10 == 0:\n",
    "        print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"wall time: {time.time() - tic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "test_x = torch.linspace(0, 1, 45, dtype=dtype, device=device)\n",
    "\n",
    "test_i = {\n",
    "    i: torch.full_like(test_x, dtype=torch.long, device=device, fill_value=i)\n",
    "    for i in range(4)\n",
    "}\n",
    "post_f, post_obs = {}, {}\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.fast_pred_var():\n",
    "    for i, ti in test_i.items():\n",
    "        post_f[i] = model(test_x, ti)\n",
    "        post_obs[i] = likelihood(post_f[i], [test_x, ti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some helpers to make plotting easier\n",
    "train_x_dict = {\n",
    "    0: train_x11, 1: train_x12, 2: train_x21, 3: train_x22, \n",
    "}\n",
    "train_y_dict = {\n",
    "    0: train_y11, 1: train_y12, 2: train_y21, 3: train_y22, \n",
    "}\n",
    "labels = {\n",
    "    0: \"task 1, outcome a\",\n",
    "    1: \"task 1, outcome b\",\n",
    "    2: \"task 2, outcome a\",\n",
    "    3: \"task 2, outcome b\",\n",
    "}\n",
    "\n",
    "f, axs = plt.subplots(2, 2, figsize=(10, 9))\n",
    "for i in range(4):\n",
    "    ax = axs[i//2, i - (i//2) * 2]\n",
    "    lower_f, upper_f = post_f[i].confidence_region()\n",
    "    lower_obs, upper_obs = post_obs[i].confidence_region()\n",
    "    ax.plot(train_x_dict[i].cpu().numpy(), train_y_dict[i].cpu().numpy(), 'k*')\n",
    "    ax.plot(test_x.cpu().numpy(), post_f[i].mean.cpu().numpy(), 'b')\n",
    "    ax.fill_between(test_x.cpu().numpy(), lower_f.cpu().numpy(), upper_f.cpu().numpy(), alpha=0.5)\n",
    "    ax.fill_between(test_x.cpu().numpy(), lower_obs.cpu().numpy(), upper_obs.cpu().numpy(), alpha=0.25, color='r')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence (f)', 'Confidence (obs)'])\n",
    "    ax.set_title(labels[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a multi-task GP trained on noise observations as a heteroskedastic noise model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_log_var = train_x\n",
    "train_i_log_var = train_i\n",
    "train_y_log_var = torch.cat([\n",
    "    train_y11_log_var,\n",
    "    train_y12_log_var,\n",
    "    train_y21_log_var,\n",
    "    train_y22_log_var,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_likelihood = GaussianLikelihood()\n",
    "noise_model = HadamardMultitaskGPModel(\n",
    "    (train_x_log_var, train_i_log_var), train_y_log_var, noise_likelihood, num_tasks=4, rank=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = _GaussianLikelihoodBase(\n",
    "    noise_covar=HeteroskedasticNoise(noise_model),\n",
    ")\n",
    "model = HadamardMultitaskGPModel((train_x, train_i), train_y, likelihood, num_tasks=4, rank=4)\n",
    "\n",
    "if dtype == torch.double:\n",
    "    likelihood.double()\n",
    "    model.double()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: To be able to train this we need to turn off the check for whether the model trains on the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},  # Includes GaussianLikelihood parameters\n",
    "], lr=0.05)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# Disabling this check is necessary when using the Heteroskedastic likelihood\n",
    "with gpytorch.settings.check_training_data(False):\n",
    "    tic = time.time()\n",
    "    n_iter = 100\n",
    "    for i in range(n_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_x, train_i)\n",
    "        loss = -mll(output, train_y, [train_x, train_i])\n",
    "        loss.backward()\n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Iter %d/%d - Loss: %.3f' % (i + 1, n_iter, loss.item()))\n",
    "        optimizer.step()\n",
    "    print(f\"wall time: {time.time() - tic:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "test_x = torch.linspace(0, 1, 45, dtype=dtype, device=device)\n",
    "\n",
    "test_i = {\n",
    "    i: torch.full_like(test_x, dtype=torch.long, device=device, fill_value=i)\n",
    "    for i in range(4)\n",
    "}\n",
    "post_f, post_obs = {}, {}\n",
    "\n",
    "\n",
    "with torch.no_grad(), gpytorch.fast_pred_var():\n",
    "    for i, ti in test_i.items():\n",
    "        post_f[i] = model(test_x, ti)\n",
    "        post_obs[i] = likelihood(post_f[i], [test_x, ti])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# some helpers to make plotting easier\n",
    "train_x_dict = {\n",
    "    0: train_x11, 1: train_x12, 2: train_x21, 3: train_x22, \n",
    "}\n",
    "train_y_dict = {\n",
    "    0: train_y11, 1: train_y12, 2: train_y21, 3: train_y22, \n",
    "}\n",
    "labels = {\n",
    "    0: \"task 1, outcome a\",\n",
    "    1: \"task 1, outcome b\",\n",
    "    2: \"task 2, outcome a\",\n",
    "    3: \"task 2, outcome b\",\n",
    "}\n",
    "\n",
    "f, axs = plt.subplots(2, 2, figsize=(10, 9))\n",
    "for i in range(4):\n",
    "    ax = axs[i//2, i - (i//2) * 2]\n",
    "    lower_f, upper_f = post_f[i].confidence_region()\n",
    "    lower_obs, upper_obs = post_obs[i].confidence_region()\n",
    "    ax.plot(train_x_dict[i].cpu().numpy(), train_y_dict[i].cpu().numpy(), 'k*')\n",
    "    ax.plot(test_x.cpu().numpy(), post_f[i].mean.cpu().numpy(), 'b')\n",
    "    ax.fill_between(test_x.cpu().numpy(), lower_f.cpu().numpy(), upper_f.cpu().numpy(), alpha=0.5)\n",
    "    ax.fill_between(test_x.cpu().numpy(), lower_obs.cpu().numpy(), upper_obs.cpu().numpy(), alpha=0.25, color='r')\n",
    "    ax.set_ylim([-3, 3])\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence (f)', 'Confidence (obs)'])\n",
    "    ax.set_title(labels[i])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
